# United-Planet-Internship
Given a csv file of 60 survey responses across five questions, I prepared the content by splicing long sentences, and removing punctuation/extra spaces/capital letters using Python Data Frames. I then used nltk.word_tokenize() to find the most frequent words for each survey question. Results were summarized in a powerpoint sent to one of my supervisors to help make decisions on program planning. 


